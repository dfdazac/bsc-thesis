<?xml version="1.0" encoding="UTF-8"?>

<ToolboxConfiguration version="2015a"> 
  <Plan> 
    <ContextConfig>default</ContextConfig>  
    <SUMO>default</SUMO>  
    <LevelPlot>default</LevelPlot>  
    <Simulator>D:\Google Drive\My Docs\UD\Proyecto de Grado\Trabajo\Objetivo 2\Intento 2\1 Surrogate Modeling\2 Modeling\SUMO Files\motorSimulator.xml</Simulator>  
    <Run name="" repeat="1"> 
      <InitialDesign>empty</InitialDesign>  
      <DataSource>scatteredDataset</DataSource>  
      <ModelBuilder>rbfnngenetic</ModelBuilder>  
      <Measure type="CrossValidation" target="0.01" errorFcn="averageEuclideanError" use="on"/>  
      <Measure type="SampleError" errorFcn="averageEuclideanError" use="off"/>  
      <Outputs> 
        <Output name="out"/> 
      </Outputs> 
    </Run>
  </Plan>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- ContextConfig contains configuration options global to the toolbox behavior -->  
  <ContextConfig id="default"> 
    <!-- Specifies the directory to use to store the results, logs, ... 
		     An absolute path can be specified, if not it is relative to the project directory. -->  
    <OutputDirectory>output</OutputDirectory>  
    <!-- Several options for configuring the intermediate plots can be found here -->  
    <PlotOptions> 
      <!-- save the latest best sumo model to disk: -->  
      <!-- as Matlab .mat file and if plotModels=true as image -->  
      <Option key="saveBestModel" value="true"/>  
      <!-- save all intermediate sumo models to disk as Matlab .mt file -->  
      <!-- as Matlab .mat file and if plotModels=true as image -->  
      <!-- warning: this may consume quite some harddisk space -->  
      <Option key="saveIntermediateModels" value="false"/>  
      <!-- plot models -->  
      <Option key="plotModels" value="false"/>  
      <!-- Style of the plot window -->  
      <!-- Requires restarting Matlab: {'normal' or 'docked'} -->  
      <Option key="WindowStyle" value="normal"/>  
      <!-- contours are  only available for 2 dimensions -->  
      <!-- also show the contour lines underneath a surface plot -->  
      <Option key="withContour" value="true"/>  
      <!-- use a contour plot instead of a surface plot -->  
      <Option key="plotContour" value="false"/>  
      <!-- also plot the model uncertainty, only supported by some models types -->  
      <Option key="plotUncertainty" value="false"/>  
      <!--
			Other options to customize plotting:
			
			<Option key="plotPoints" value="true"/>
			<Option key="lighting" value="false"/>
			<Option key="slices" value="3"/>
			<Option key="grayScale" value="false"/>
			<Option key="meshSize" value="41"/>
			<Option key="fontSize" value="14"/>
			<Option key="logScale" value="false"/>
			-->  
      <!-- Output file format of the plot: png (default),eps,bmp,jpg,... -->  
      <Option key="outputType" value="png"/> 
    </PlotOptions>  
    <!-- Keep models from previous model iterations.
		     See:
		     http://www.sumowiki.intec.ugent.be/index.php/FAQ#I_sometimes_see_the_error_of_the_best_model_go_up.2C_shouldn.27t_it_decrease_monotonically.3F
			-->  
    <Option key="keepOldModels" value="off"/>  
    <!-- If set to on the parallelMode option will check if the Matlab Parallel Computing Toolbox
		is installed.  If so, model construction will occur in parallel where possible, thus speeding
		things up. Note that this option is still somewhat experimental.  If you get weird problems switch it off again. -->  
    <Option key="parallelMode" value="on"/>  
    <!-- Set to true if the SUMO will be used for a classification problem -->  
    <Option key="classificationMode" value="false"/>  
    <!-- For classification problem, the number of classes -->  
    <Option key="numberOfClasses" value="0"/>  
    <!-- Should the order of samples be preserved as selected by the Initial Design/Sample Selector -->  
    <Option key="preserveOrder" value="true"/>  
    <!--
		Configuration options for the profilers.  Profilers allow you to track the modeling process and understand what happens.
		Within a profiler block, one or more <Output type="type"/> specifiers should be present. Possible types are toFile, toPanel, toTable, and toImage.
		-->  
    <Profiling> 
      <!--
			You can restrict the available profilers to use by specifying a wildcard to disable the docked output if you dont want a window containing all the profilers.
			To select all profilers, simply put ".*"
			-->  
      <Profiler name=".*BestModel.*|.*SampleError.*" enabled="true"> 
        <!-- note that the toImage/toPanel handlers are quite expensive to use, removing them will speed things up -->  
        <Output type="toPanel"/>  
        <Output type="toImage"/>  
        <Output type="toFile"/> 
      </Profiler> 
    </Profiling> 
  </ContextConfig>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- How much logging information should the toolbox produce -->  
  <Logging> 
    <!-- Root logger -->  
    <RootLogger> 
      <!-- log all run-specific information in the main log as well -->  
      <Option key="runsInMainLog" value="true"/>  
      <!-- Set the default logging level for the root logger -->  
      <Option key="Level" value="INFO"/>  
      <!-- Specify the handlers to create in the root logger
			 (all loggers are children of the root logger).  The handlers determine
			 where logging output is sent to. 
			 
			 Possible levels are: OFF, SEVERE, WARNING, INFO, FINE, FINER, FINEST, ALL
			 -->  
      <Handlers> 
        <!-- Configure ConsoleHandler (= output to the screen) -->  
        <ConsoleHandler> 
          <Option key="Level" value="ALL"/> 
        </ConsoleHandler>  
        <!-- Configure FileHandler (= output to file)-->  
        <FileHandler> 
          <Option key="Level" value="ALL"/>  
          <Option key="Pattern" value="Sumo.log"/> 
        </FileHandler> 
      </Handlers> 
    </RootLogger>  
    <!-- The Options here specify the level for a specific logger
		      This configures which log messages actually get generated -->  
    <!-- <Option key="loggername" value="level" /> -->  
    <Option key="iminds.sumo" value="FINEST"/>  
    <Option key="Matlab" value="FINEST"/> 
  </Logging>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- A Level plot is a kind error histogram of the best model over time -->  
  <LevelPlot id="default" type="LevelPlot" combineOutputs="true"> 
    <!--
		This option enables the levelPlotProfiler (be sure to enable it in the  profilers section too). A sample evaluator should provide the reference
		data set over which the error should be calculated.
		-->  
    <Option key="makeLevelPlots" value="off"/>  
    <!-- This tag defines the DataSource that is used by the levelplot  (it needs to get its data from somewhere) -->  
    <DataSource type="iminds.sumo.datasources.datasets.ScatteredDatasetDataSource"> 
      <!-- <Option key="id" value="validation"/> --> 
    </DataSource> 
  </LevelPlot>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Important options that influence the whole modeling process -->  
  <SUMO id="default" type="SUMO"> 
    <!--Should a movie be created of the model plots when the toolbox has terminated-->  
    <Option key="createMovie" value="yes"/>  
    <!-- The minimum amount of samples alotted to *EACH RUN*, dont stop untill we have at least this many samples -->  
    <Option key="minimumTotalSamples" value="0"/>  
    <!--The maximum amount of samples alotted to *EACH RUN*, stop the run and proceed to the next if this number of samples is exceeded (set to Inf to disable) -->  
    <Option key="maximumTotalSamples" value="Inf"/>  
    <!--The amount of time (in minutes) alotted to *EACH RUN*, stop the run and proceed to the next if this number is exceeded (set to Inf to disable) -->  
    <Option key="maximumTime" value="Inf"/>  
    <!--
		The maximum number of adaptive modeling iterations  alotted to *EACH RUN*,
		stop the run and proceed to the	next if this number is exceeded
		(set to Inf to disable).
		-->  
    <Option key="maxModelingIterations" value="Inf"/>  
    <!--
        The seed for the random number generator
        If not given the seed will be generated based on the time.
		-->  
    <!-- <Option key="randomSeed" value="888"/> -->  
    <!--
		Stop the main loop if a fatal error occurs in the sample evaluator, if set to false
		the toolbox will switch to adaptive modeling mode (further sampling is switched off).
		-->  
    <Option key="stopOnError" value="true"/>  
    <!-- Minimum amount of samples that are to be evaluated from the initial sample set before the modeling process starts. 
		     This can either be an absolute number (e.g., 23) or a percentage (e.g., 95%) -->  
    <Option key="minimumInitialSamples" value="100%"/>  
    <!-- 
            Minimum and maximum number of pending samples allowed at any time in the toolbox. 
            Pending samples are samples which have not yet been evaluated and thus 
            do not have an output value.
        -->  
    <Option key="minimumSamples" value="50"/>  
    <Option key="maximumSamples" value="100"/>  
    <!--
			How many % of the pending samples should be at least retrieved every iteration:
			0 %: just takes the samples that have been evaluated and build a model
			100 %: wait until all selected samples have been evaluated
            Do not include the % sign when specifying the value
		-->  
    <Option key="minimumAdaptiveSamples" value="100"/>  
    <!-- Must samples be checked against the constraints before they are submitted for evaluation? -->  
    <Option key="newSamplesMustSatisfyConstraints" value="yes"/>  
    <!-- Must the entire dataset be used in adaptive modeling mode or not?
			 true: only the initial design is evaluated, and is used in adaptive modeling mode
			 false: the entire dataset is loaded immediately and used in adaptive modeling mode
		-->  
    <Option key="adaptiveModelingInitialDesignOnly" value="no"/>  
    <!-- Do we rebuild the best models if new samples arrive,
             while keeping their existing parameters (default: on)
        <Option key="rebuildBestModels" value="off" />
        --> 
  </SUMO>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!--Use this if you data generator is a native executable, shell script, or java class-->  
  <DataSource id="local" type="iminds.sumo.datasources.LocalDataSource"> 
    <!-- Maximum number of times to resubmit a point (e.g., in case something went wrong) -->  
    <Option key="maxResubmissions" value="1"/>  
    <!-- If a sample takes longer than "sampleTimeout*average evaluation time of one sample" 
		seconds to evaluate it is removed from the pending list (set to -1 to disable) -->  
    <Option key="sampleTimeout" value="-1"/>  
    <!-- Can be set to "java" for java executables, to "external" for platform-specific
		     binaries/scripts and to nothing at all for auto-detection.-->  
    <Option key="simulatorType" value=""/>  
    <!-- Can be set to a number of seconds, if one simulator evaluation exceeds this timeout,
		     the simulation is aborted -->  
    <!-- <Option key="timeout" value="12"/> -->  
    <!-- Number of samples to evaluate concurrently, useful if you have a dual or multi-core machine -->  
    <Option key="threadCount" value="1"/> 
  </DataSource>  
  <!-- Evaluate samples using a matlab script (ie. your simulator is a matlab script) -->  
  <DataSource id="matlab" type="MatlabDirectDataSource"/>  
  <!-- Evaluate samples using a matlab script (ie. your simulator is a matlab script) -->  
  <!-- DEPRECATED: too much overhead with java -->  
  <DataSource id="matlabOld" type="iminds.sumo.datasources.matlab.MatlabDataSource"> 
    <!-- Maximum number of times to resubmit a point (e.g., in case something went wrong) -->  
    <Option key="maxResubmissions" value="1"/>  
    <!-- If a sample takes longer than "sampleTimeout*average evaluation time of one sample" 
		seconds to evaluate it is removed from the pending list (set to -1 to disable) -->  
    <Option key="sampleTimeout" value="-1"/> 
  </DataSource>  
  <!-- Evaluate samples using a gridded dataset -->  
  <DataSource id="griddedDataset" type="iminds.sumo.datasources.datasets.GriddedDatasetDataSource"> 
    <!-- Using an ID you can specify which dataset from the simulator file to use -->  
    <!-- <Option key="id" value="someDataset"/> --> 
  </DataSource>  
  <!-- Evaluate samples using a scattered dataset -->  
  <DataSource id="scatteredDataset" type="iminds.sumo.datasources.datasets.ScatteredDatasetDataSource"> 
    <!-- Using an ID you can specify which dataset from the simulator file to use -->  
    <!-- <Option key="id" value="someDataset"/> --> 
  </DataSource>  
  <DataSource id="directScatteredDataset" type="DatasetDirectDataSource"> 
    <!-- Using an ID you can specify which dataset from the simulator file to use -->  
    <!-- <Option key="id" value="someDataset"/> --> 
  </DataSource>  
  <!--Evaluate samples on a SGE administered cluster through a remote, ssh reachable frontnode-->  
  <DataSource id="calcua" type="iminds.sumo.datasources.distributed.sge.RemoteSGEDataSource"> 
    <!-- Maximum number of times to resubmit a point (e.g., in case something went wrong) -->  
    <Option key="maxResubmissions" value="1"/>  
    <!-- If a sample takes longer than "sampleTimeout*average evaluation time of one sample" 
		     seconds to evaluate it is removed from the pending list (set to -1 to disable) -->  
    <Option key="sampleTimeout" value="-1"/>  
    <!--The platform specs of the cluster-->  
    <Executable platform="linux" arch="x86_64"/>  
    <Backend id="remoteSGE" type="iminds.sumo.datasources.distributed.sge.RemoteSGEBackend"> 
      <!--ssh user name to login on the front node-->  
      <Option key="user" value="dgorisse"/>  
      <!--Submissions happen from this front node, you need to have key-based ssh authentication-->  
      <Option key="frontNode" value="submit.calcua.ua.ac.be"/>  
      <!--Directory on the front node where input/output files, dependencies, etc. are stored-->  
      <Option key="remoteDirectory" value="/storeA/users/dgorisse/output"/>  
      <!--poll for result files every xx seconds-->  
      <Option key="pollInterval" value="20"/>  
      <!--queues we can submit to-->  
      <Option key="queues" value="all.q,fast.q"/>  
      <!--check for faster queues (more slots available) every xx seconds-->  
      <Option key="queueRevisionRate" value="10"/>  
      <!--script on the frontnode that sets up the necessary shell environment-->  
      <Option key="environmentCommand" value=". ~/.profile;"/> 
    </Backend> 
  </DataSource>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Don't select any new samples, useful when modeling multiple outputs, and you don't want to involve one of these outputs in the sampling process. -->  
  <SequentialDesign id="empty" type="EmptySequentialDesign" combineOutputs="false"/>  
  <!-- Selects new samples randomly in the design space. -->  
  <SequentialDesign id="random" type="RandomSequentialDesign" combineOutputs="false"/>  
  <!-- This sample selector uses a Delaunay triangulation of the data to select samples in locations far from previous samples, or in locations where the estimated model error is largest.
    This algorithm uses QHull, which is very slow for high dimensions, so you should only use this sample selector for less than 6D and for less than 1000 samples. -->  
  <SequentialDesign id="delaunay" type="PipelineSequentialDesign" combineOutputs="false"> 
    <CandidateGenerator type="DelaunayCandidateGenerator"/>  
    <CandidateRanker type="modelDifference"> 
      <Option key="nrModels" value="2"/> 
    </CandidateRanker>  
    <CandidateRanker type="delaunayVolume"/>  
    <MergeCriterion type="WeightedAverage" weights="[1 1]"/> 
  </SequentialDesign>  
  <!-- A space-filling sampling algorithm that generates points based on both the maximin distance and the projected distance. -->  
  <SequentialDesign id="density" type="PipelineSequentialDesign" combineOutputs="false"> 
    <CandidateGenerator type="ProjectedThresholdRandomCandidateGenerator"> 
      <Option key="candidatesPerSample" value="500"/>  
      <Option key="alpha" value="0.5"/> 
    </CandidateGenerator>  
    <CandidateRanker type="maximinDistance" scaling="none"/>  
    <MergeCriterion type="ClosenessThreshold"/> 
  </SequentialDesign>  
  <!-- A space-filling sampling algorithm that generates points based on the projected distance and then locally optimizes these points
    for intersite distance. This method produces slightly better designs than the density method, but is also a little bit slower. -->  
  <SequentialDesign id="density-optimizer" type="OptimizeCriterion" combineOutputs="false"> 
    <CandidateGenerator type="ProjectedDistanceGridCandidateGenerator"> 
      <Option key="alpha" value="0.5"/> 
    </CandidateGenerator>  
    <!-- This criterion has to be solved to choose new samples, one can choose the optimizer used here -->  
    <Optimizer type="ProjectedDistanceGridOptimizer"/>  
    <CandidateRanker type="maximinDistance" scaling="none" sqrt="false"/>  
    <Option key="debug" value="off"/> 
  </SequentialDesign>  
  <!-- A space-filling sampling algorithm based on global optimization of a projective / intersite distance surface. Because
    this is very hard, Fuzzy Logic is applied to soften some constraints and help the optimization algorithm. -->  
  <SequentialDesign id="fuzzy-density" type="OptimizeCriterion" combineOutputs="false"> 
    <CandidateGenerator type="TPLatinHypercubeDesign"> 
      <Option key="points" value="100"/> 
    </CandidateGenerator>  
    <Optimizer type="PSOtOptimizer"> 
      <Option key="popSize" value="50"/> 
    </Optimizer>  
    <CandidateRanker type="fuzzySpaceFilling" scaling="none"/>  
    <Option key="debug" value="off"/> 
  </SequentialDesign>  
  <!-- An adaptive sample selection algorithm (error based), driven by the evaluation of your model on a dense grid, which selects samples in locations where the model error is estimated to be the largest. -->  
  <SequentialDesign id="error" type="PipelineSequentialDesign" combineOutputs="false"> 
    <CandidateGenerator type="GridCandidateGenerator"/>  
    <CandidateRanker type="modelDifference"> 
      <Option key="nrModels" value="4"/> 
    </CandidateRanker>  
    <MergeCriterion type="ClosenessThreshold"> 
      <!-- Closeness threshold, Double -->  
      <Option key="closenessThreshold" value="0.05"/>  
      <!-- Set a % of the maximumSamples to randomly chosen -->  
      <Option key="randomPercentage" value="20"/> 
    </MergeCriterion> 
  </SequentialDesign>  
  <!-- A highly adaptive sampling algorithm which performs a trade-off between exploration (filling up the design space as equally as possible)
    and exploitation (selecting data points in highly nonlinear regions). lola-voronoi is the only sample selector which currently supports
    multiple outputs, auto-sampled inputs and constraints. -->  
  <SequentialDesign id="lola-voronoi" type="LOLAVoronoiSequentialDesign" combineOutputs="false"> 
    <!-- Number of frequency values returned for each submitted sample. Only used with auto-sampled inputs. -->  
    <Option key="frequencies" value="11"/>  
    <!-- Whether a directed search should be performed while performing exploitation. Allows for more aggressive exploitation. -->  
    <Option key="directedSearch" value="false"/>  
    <!-- Distance metric to use. Note: distance metrics of the individual rankers will be overruled! -->  
    <Distance type="EuclideanDistance"/>  
    <ExploitationSampleRanker type="LOLASampleRanker"> 
      <!-- Integer between 2 and 20 -->  
      <Option key="neighbourhoodSize" value="2"/> 
    </ExploitationSampleRanker>  
    <ExplorationSampleRanker type="VoronoiSampleRanker"/> 
  </SequentialDesign>  
  <!-- 
    Follow-up on LOLA-Voronoi. Reduces compression dramatically, especially for high dimensional
    problems
    -->  
  <SequentialDesign id="flola-voronoi" type="LOLAVoronoiSequentialDesign" combineOutputs="false"> 
    <!-- Number of frequency values returned for each submitted sample. Only used with auto-sampled inputs. -->  
    <Option key="frequencies" value="11"/>  
    <!-- Distance metric to use. Note: distance metrics of the individual rankers will be overruled! -->  
    <Distance type="EuclideanDistance"/>  
    <ExploitationSampleRanker type="FLOLASampleRanker"> 
      <Option key="K" value="4"/>  
      <Option key="L" value="2"/> 
    </ExploitationSampleRanker>  
    <ExplorationSampleRanker type="VoronoiSampleRanker"/> 
  </SequentialDesign>  
  <SequentialDesign id="lola" type="LOLASampleRanker" combineOutputs="false"> 
    <!-- Distance metric to use. Note: distance metrics of the individual rankers will be overruled! -->  
    <Distance type="EuclideanDistance"/> 
  </SequentialDesign>  
  <SequentialDesign id="voronoi" type="VoronoiSampleRanker" combineOutputs="false"> 
    <!-- Distance metric to use. Note: distance metrics of the individual rankers will be overruled! -->  
    <Distance type="EuclideanDistance"/> 
  </SequentialDesign>  
  <!-- A sampling algorithm aimed at supressing poles in rational models by sampling them (only for Rational models) -->  
  <SequentialDesign id="rationalPoleSupression" type="OptimizeCriterion" combineOutputs="false"> 
    <!-- This criterion has to be solved to choose new samples, one can choose the optimizer used here -->  
    <Optimizer>patternsearch</Optimizer>  
    <CandidateRanker type="rationalPoleSupression" scaling="none"/>  
    <CandidateRanker type="modelDifference" scaling="none"/>  
    <!--
        when debug is 'on' a contour plot of the criterion function is drawn every iteration.
        Together with the current samples and the chosen samples
        -->  
    <Option key="debug" value="off"/> 
  </SequentialDesign>  
  <!-- A sampling algorithm aimed at optimization problems (only for Kriging and RBF) -->  
  <SequentialDesign id="expectedImprovement" type="OptimizeCriterion" combineOutputs="false"> 
    <CandidateRanker type="expectedImprovement" scaling="none"/>  
    <CandidateRanker type="maxvar" scaling="none"/>  
    <!-- The previous criteria have to be solved to choose new samples, one can choose the optimizer used here -->  
    <Optimizer>directOptimizer</Optimizer>  
    <!--
        when debug is 'on' a contour plot of the criterion function is drawn every iteration.
        Together with the current samples and the chosen samples
        -->  
    <Option key="debug" value="on"/> 
  </SequentialDesign>  
  <!-- A sampling algorithm aimed at multiobjective optimization problems (only for Kriging and RBF) -->  
  <SequentialDesign id="paretoPoIHv" type="OptimizeCriterion" combineOutputs="true"> 
    <CandidateRanker type="hypervolumePoI" scaling="none"> 
      <ParetoFront>paretoFront</ParetoFront> 
    </CandidateRanker>  
    <CandidateRanker type="maxvar" scaling="none"/>  
    <!-- The previous criteria have to be solved to choose new samples, one can choose the optimizer used here -->  
    <CandidateGenerator type="RandomCandidateGenerator"> 
      <Option key="candidatesPerSample" value="20"/> 
    </CandidateGenerator>  
    <Optimizer>fmincon</Optimizer>  
    <!--
        when debug is 'on' a contour plot of the criterion function is drawn every iteration.
        Together with the current samples and the chosen samples
        -->  
    <Option key="debug" value="off"/> 
  </SequentialDesign>  
  <ParetoFront id="paretoFront" type="ParetoFront"> 
    <Option key="strategy" value="binary"/>  
    <!-- Binary search -->  
    <!--
        The WFG strategy is much faster but requires compilation of
        the corresponding mex files with: "make mexfiles"
        -->  
    <!--<Option key="strategy" value="wfg" />-->  
    <Option key="levelsOfImprovement" value="[0;Inf]"/>  
    <!-- Pareto front plot -->  
    <Option key="debug" value="false"/> 
  </ParetoFront>  
  <!-- A sampling algorithm aimed at optimization problems (only for Kriging and RBF) -->  
  <SequentialDesign id="knowledgeGradient" type="OptimizeCriterion" combineOutputs="false"> 
    <!-- This criterion has to be solved to choose new samples, one can choose the optimizer used here -->  
    <Optimizer>directOptimizer</Optimizer>  
    <CandidateRanker type="knowledgeGradient" scaling="none"> 
      <Optimizer>directOptimizer</Optimizer> 
    </CandidateRanker>  
    <CandidateRanker type="maxvar" scaling="none"/>  
    <!--
        when debug is 'on' a contour plot of the criterion function is drawn every iteration.
        Together with the current samples and the chosen samples
        -->  
    <Option key="debug" value="off"/> 
  </SequentialDesign>  
  <!-- A sampling algorithm for constrained optimization -->  
  <SequentialDesign id="constrainedExpectedImprovement" type="OptimizeCriterion" combineOutputs="true"> 
    <!-- This criterion has to be solved to choose new samples, one can choose the optimizer used here -->  
    <Optimizer>directOptimizer</Optimizer>  
    <CandidateRanker type="AggregateObjective" scaling="none"> 
      <Option key="aggregate" value="@prod"/>  
      <Option key="constraintMode" value="true"/>  
      <Option key="objectivesIdx" value="[1 0]"/>  
      <!-- first output is objective, second output is constraint -->  
      <!-- First output is directed to this CandidateRanker -->  
      <CandidateRanker type="expectedImprovement" scaling="none"/>  
      <!-- Second output is directed to this CandidateRanker -->  
      <CandidateRanker type="probabilityOfFeasibility" scaling="none"/> 
    </CandidateRanker>  
    <CandidateRanker type="maxvar" scaling="none"/>  
    <!--
        when debug is 'on' a contour plot of the criterion function is drawn every iteration.
        Together with the current samples and the chosen samples
        -->  
    <Option key="debug" value="off"/> 
  </SequentialDesign>  
  <!-- LOLA-Voronoi sample selector supplemented with 1 sample at the minimum and maximum -->  
  <SequentialDesign id="extremaLOLA" type="CombinedSequentialDesign" combineOutputs="false"> 
    <!-- A highly adaptive sampling algorithm, error and density based -->  
    <SequentialDesign weight="0.8">lola-voronoi</SequentialDesign>  
    <SequentialDesign weight="0.1">sampleMinimum</SequentialDesign>  
    <SequentialDesign weight="0.1">sampleMaximum</SequentialDesign>  
    <MergeCriterion type="ClosenessThreshold"> 
      <!-- Closeness threshold, Double -->  
      <Option key="closenessThreshold" value="0.05"/>  
      <!-- Set a % of the maximumSamples to randomly chosen -->  
      <Option key="randomPercentage" value="0"/> 
    </MergeCriterion> 
  </SequentialDesign>  
  <!-- The generalized Probability of Feasibility criterion. Samples between an output range
    The output range can be specified here as bounds in the simulator configuration file -->  
  <SequentialDesign id="gProbabilityOfFeasibility" type="PipelineSequentialDesign" combineOutputs="false"> 
    <!--<Option key="debug" value="true"/>  -->  
    <CandidateGenerator type="RandomCandidateGenerator"/>  
    <CandidateRanker type="gProbabilityOfFeasibility" scaling="none"> 
      <Option key="outputRange" value="[-0.2,0.2]"/>  
      <Option key="percentage" value="false"/>  
      <Option key="regression" value="false"/> 
    </CandidateRanker>  
    <CandidateRanker type="maximinDistance" scaling="none"> 
      <Option key="scaleToZeroOne" value="true"/> 
    </CandidateRanker>  
    <MergeCriterion type="ClosenessThreshold"> 
      <!-- Closeness threshold, Double -->  
      <Option key="closenessThreshold" value="0.05"/>  
      <!-- Set a % of the maximumSamples to randomly choose -->  
      <Option key="randomPercentage" value="20"/> 
    </MergeCriterion> 
  </SequentialDesign>  
  <!-- Selects one sample at the minimum of the model. -->  
  <SequentialDesign id="sampleMinimum" type="OptimizeCriterion" combineOutputs="false"> 
    <Optimizer>patternsearch</Optimizer>  
    <CandidateRanker type="minmodel" scaling="none"/> 
  </SequentialDesign>  
  <!-- Selects one sample at the maximum of the model. -->  
  <SequentialDesign id="sampleMaximum" type="OptimizeCriterion" combineOutputs="false"> 
    <Optimizer>patternsearch</Optimizer>  
    <CandidateRanker type="maxmodel" scaling="none"/> 
  </SequentialDesign>  
  <!-- LOLA sample selector combined with error based sample selector -->  
  <SequentialDesign id="default" type="CombinedSequentialDesign" combineOutputs="false"> 
    <SequentialDesign weight="0.7">lola-voronoi</SequentialDesign>  
    <SequentialDesign weight="0.3">error</SequentialDesign>  
    <MergeCriterion type="ClosenessThreshold"> 
      <!-- Closeness threshold, Double -->  
      <Option key="closenessThreshold" value="0.05"/>  
      <!-- Set a % of the maximumSamples to randomly chosen -->  
      <Option key="randomPercentage" value="0"/> 
    </MergeCriterion> 
  </SequentialDesign>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Now we list the Adaptive Model Builders.  Each adaptive model builder is a combination
	    of a model type (svm, ann, rbf, ...) and an optimization algorithm to choose the model 
	    parameters.  Note that the list here is NOT EXHAUSTIVE for else it would simply be too long -->  
  <!-- Build rational models using a custom stochastic hillclimber to select the model parameters -->  
  <ModelBuilder id="rational" type="SequentialModelBuilder" combineOutputs="true"> 
    <!-- Maximum number of models built before selecting new samples -->  
    <Option key="maximumRunLength" value="30"/>  
    <!-- Degeneration of score if a model gets older -->  
    <Option key="decay" value=".99"/>  
    <!-- Size of the best model history -->  
    <Option key="historySize" value="15"/>  
    <!-- One of best, last. When set to best the best `historySize' models are kept,
		 - - when set to last, the last `historySize' models are kept -->  
    <Option key="strategy" value="best"/>  
    <!-- <Option key="strategy" value="window"/> -->  
    <ModelFactory type="RationalFactory"> 
      <!-- Bounds for the weights of the rational modeller -->  
      <Option key="weightBounds" value="1,40"/>  
      <!-- Bounds for the percentage of degrees of freedom wrt number of samples -->  
      <Option key="percentBounds" value="1,100"/>  
      <!-- Regardless of the percentage bounds, never use more than this many degrees of freedom -->  
      <Option key="maxDegrees" value="80"/>  
      <!-- When randomizing rational flags, what percentage should be set -->  
      <Option key="percentRational" value="70"/>  
      <!-- If a variable is named "f" of "frequency" it will be modelled differently, if this is set to auto,
			 - - If this field is set to a variable name, that variable will be considered to be the frequency -->  
      <Option key="frequencyVariable" value="auto"/>  
      <!-- Base function for interpolation, one of chebyshev, power, legendre -->  
      <Option key="basis" value="power"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build rational models using a genetic algorithm -->  
  <ModelBuilder id="rationalgenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!--See that matlab gads toolbox documentation for more information on the options-->  
    <Option key="restartStrategy" value="continue"/>  
    <Option key="populationType" value="custom"/>  
    <Option key="populationSize" value="40"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="maxGenerations" value="20"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="stallGenLimit" value="5"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory type="RationalFactory"> 
      <Option key="crossoverFcn" value="crossover"/>  
      <Option key="mutationFcn" value="mutation"/>  
      <Option key="creationFcn" value="createInitialPopulation"/>  
      <!-- Use the next three functions instead of the previous three if you set the
			      population type to doubleVector -->  
      <!--<Option key="creationFcn" value="@gacreationuniform"/>
			<Option key="crossoverFcn" value="@crossoverheuristic"/>
			<Option key="mutationFcn" value="@mutationadaptfeasible"/>-->  
      <!-- Bounds for the weights of the rational modeller -->  
      <Option key="weightBounds" value="1,40"/>  
      <!-- Bounds for the percentage of degrees of freedom wrt number of samples -->  
      <Option key="percentBounds" value="1,100"/>  
      <!-- Regardless of the percentage bounds, never use more than this many degrees of freedom -->  
      <Option key="maxDegrees" value="80"/>  
      <!-- When randomizing rational flags, what percentage should be set -->  
      <Option key="percentRational" value="70"/>  
      <!-- If a variable is named "f" of "frequency" 
				it will be modelled differently, if this is set to auto -->  
      <!-- If this field is set to a variable name, that variable will be considered to be the frequency -->  
      <Option key="frequencyVariable" value="auto"/>  
      <!-- Base function for interpolation, one of chebyshev, power, legendre -->  
      <Option key="basis" value="power"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Generate Rational models using PSO -->  
  <ModelBuilder id="rationalpso" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="PSOtOptimizer"> 
      <Option key="typePSO" value="0"/>  
      <Option key="seedPSO" value="1"/>  
      <Option key="popSize" value="10"/>  
      <Option key="maxiters" value="10"/>  
      <Option key="epochInertia" value="8"/>  
      <Option key="gradientTermination" value="8"/> 
    </Optimizer>  
    <ModelFactory type="RationalFactory"> 
      <!-- Bounds for the weights of the rational modeller -->  
      <Option key="weightBounds" value="1,40"/>  
      <!-- Bounds for the percentage of degrees of freedom wrt number of samples -->  
      <Option key="percentBounds" value="1,100"/>  
      <!-- Regardless of the percentage bounds, never use more than this many degrees of freedom -->  
      <Option key="maxDegrees" value="80"/>  
      <!-- When randomizing rational flags, what percentage should be set -->  
      <Option key="percentRational" value="70"/>  
      <!-- If a variable is named "f" of "frequency" 
				it will be modelled differently, if this is set to auto -->  
      <!-- If this field is set to a variable name, that variable will be considered to be the frequency -->  
      <Option key="frequencyVariable" value="auto"/>  
      <!-- Base function for interpolation, one of chebyshev, power, legendre -->  
      <Option key="basis" value="power"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build polynomial models with a fixed order -->  
  <ModelBuilder id="polynomialfixed" type="ModelBuilder" combineOutputs="false"> 
    <ModelFactory type="PolynomialFactory"> 
      <!-- Specifies the structure of the polynomial -->  
      <!-- Expects matlab matrix: Element (i,j) is the exponent of variable i for term j.  -->  
      <Option key="degrees" value="[0 0;1 0;0 1;1 1;2 0;0 2;2 2]"/>  
      <!-- Equals to 1+x+y+xy+xx+yy+xxyy -->  
      <!-- Base function for interpolation, one of chebyshev, power, legendre -->  
      <Option key="basis" value="power"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build Radial Basis Function models -->  
  <ModelBuilder id="rbf" type="SequentialModelBuilder" combineOutputs="false"> 
    <!-- Maximum number of models built before selecting new samples -->  
    <Option key="maximumRunLength" value="20"/>  
    <!-- Degeneration of score if a model gets older -->  
    <Option key="decay" value=".9"/>  
    <!-- Size of the best model history -->  
    <Option key="historySize" value="15"/>  
    <!-- One of best, last. When set to best the best `historySize' models are kept,
		- - when set to last, the last `historySize' models are kept -->  
    <Option key="strategy" value="best"/>  
    <!-- <Option key="strategy" value="window"/> -->  
    <ModelFactory type="RBFFactory"> 
      <!-- Bounds for the shape parameter -->  
      <Option key="multipleBasisFunctionsAllowed" value="true"/>  
      <BasisFunction>rbfGaussian</BasisFunction>  
      <BasisFunction>rbfMultiquadric</BasisFunction>  
      <BasisFunction>rbfExponential</BasisFunction>  
      <Option key="regression" value="-1,0,1,2"/>  
      <!-- Specify which implementation to use, currently, 'Direct', 'AP', 'Greedy'
			are supported.
			
			'directFit' solves the direct problem by inverting the interpolation
			matrix
			'AlternatingProjections' uses an alternating projections method when the system gets
			too large. This is *MUCH* slower than 'directFit', and doesn't
			guarantee convergence, use with caution
			'MultiPointGreedy' uses a one point greedy algorithm for selecting the 
			interpolation centers. Same remark applies as with 'AlternatingProjections'
			-->  
      <Option key="solver" value="directFit"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build Radial Basis Function models using a genetic algorithm -->  
  <ModelBuilder id="rbfgenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <Option key="restartStrategy" value="continue"/>  
    <!--See that matlab gads toolbox documentation for more information on the options-->  
    <Option key="populationType" value="custom"/>  
    <Option key="populationSize" value="15"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory type="RBFFactory"> 
      <Option key="crossoverFcn" value="crossover"/>  
      <Option key="mutationFcn" value="mutation"/>  
      <Option key="creationFcn" value="createInitialPopulation"/>  
      <!-- Bounds for the shape parameter -->  
      <Option key="multipleBasisFunctionsAllowed" value="true"/>  
      <BasisFunction>rbfGaussian</BasisFunction>  
      <BasisFunction>rbfMultiquadric</BasisFunction>  
      <BasisFunction>rbfExponential</BasisFunction>  
      <Option key="regression" value="-1,0,1,2"/>  
      <Option key="solver" value="directFit"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <BasisFunction id="rbfGaussian" type="BasisFunction" name="rbfGaussian"> 
    <Parameter name="alpha" min=".1" max="5" scale="ln" duplicate="no"/> 
  </BasisFunction>  
  <BasisFunction id="rbfMultiquadric" type="BasisFunction" name="rbfMultiquadric"> 
    <Parameter name="alpha" min=".1" max="5" scale="ln" duplicate="no"/> 
  </BasisFunction>  
  <BasisFunction id="rbfExponential" type="BasisFunction" name="rbfExponential"> 
    <Parameter name="alpha1" min=".1" max="5" scale="ln" duplicate="no"/>  
    <Parameter name="alpha2" min=".5" max="2" scale="lin" duplicate="no"/> 
  </BasisFunction>  
  <!--<BasisFunction id="rbfBiharmonic type="BasisFunction" "name="rbfBiharmonic">
        <Parameter name="alpha" min=".1"    max="5"    scale="ln" duplicate="no"/>
    </BasisFunction>-->  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Build GP using pattern search -->  
  <ModelBuilder id="gpmldirect" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer id="opt" type="DirectOptimizer"> 
      <Option key="maxits" value="100"/>  
      <Option key="maxevals" value="20"/> 
    </Optimizer>  
    <ModelFactory type="GaussianProcessFactory"/> 
  </ModelBuilder>  
  <!-- Build GP using pattern search -->  
  <ModelBuilder id="gpmlps" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="500"/>  
      <Option key="maxFunEvals" value="100"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <ModelFactory type="GaussianProcessFactory"> 
      <!-- use FITC for large datasets -->  
      <Option key="useFITC" value="true"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build Gaussian Process models using a GA -->  
  <ModelBuilder id="gpmlgenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!--See that matlab gads toolbox documentation for more information on the options-->  
    <Option key="populationType" value="doubleVector"/>  
    <Option key="populationSize" value="15"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory type="GaussianProcessFactory"> 
      <Option key="creationFcn" value="@gacreationuniform"/>  
      <Option key="crossoverFcn" value="@crossoverheuristic"/>  
      <Option key="mutationFcn" value="@mutationadaptfeasible"/>  
      <!--
			<Option key="crossoverFcn" value="crossover"/>
			<Option key="mutationFcn" value="mutation"/>
			<Option key="creationFcn" value="createInitialPopulation"/>
            --> 
    </ModelFactory> 
  </ModelBuilder>  
  <ModelBuilder id="gpml" type="ModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="500"/>  
      <Option key="maxFunEvals" value="100"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <ModelFactory type="GaussianProcessFactory"> 
      <!-- use FITC for large datasets -->  
      <Option key="useFITC" value="false"/>  
      <!-- The type of basis functions to use -->  
      <Option key="meanFunction" value="{@meanZero}"/>  
      <!-- mean function -->  
      <Option key="covarianceFunction" value="{@covMaternard, 3}"/>  
      <!-- covariance function -->  
      <Option key="likelihoodFunction" value="{'likGauss'}"/>  
      <!-- likelihood function -->  
      <Option key="inferenceFunction" value="@infExact"/>  
      <!-- inference function -->  
      <!-- The initial hyperparameter values -->  
      <Option key="initialMeanHyp" value="0"/>  
      <Option key="initialCovHyp" value="0"/>  
      <Option key="initialLikHyp" value="0"/>  
      <!-- The bounds on the hyperparameters -->  
      <Option key="boundsMeanHyp" value="[-1; 1]"/>  
      <Option key="boundsCovHyp" value="[-5 -1 -1; 5 1 1]"/>  
      <Option key="boundsLikHyp" value="[-5; 1]"/>  
      <!--   Optimization method for the MLE -->  
      <!-- Optional: if not given the SUMO Measure will be optimized -->  
      <Optimizer>fminconWithDerivatives</Optimizer> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Build kriging models using Simulated Annealing -->  
  <ModelBuilder id="krigingsim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabSimAnnealing"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <!-- See the documentaion for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="regressionFunction" value="regpoly1"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <BasisFunction>corrgauss</BasisFunction> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build kriging models using pattern search -->  
  <ModelBuilder id="krigingps" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <ModelFactory type="KrigingFactory"> 
      <Option key="regressionFunction" value="regpoly1"/>  
      <Option key="multipleBasisFunctionsAllowed" value="true"/>  
      <BasisFunction>corrgauss</BasisFunction>  
      <BasisFunction>correxp</BasisFunction> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build kriging models using the matlab optimization toolbox -->  
  <ModelBuilder id="krigingoptim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabOptimizer"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <!-- See the documentaion for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="regressionFunction" value="regpoly1"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <BasisFunction>corrgauss</BasisFunction> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build kriging models using a genetic algorithm-->  
  <ModelBuilder id="kriginggenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- If you specify "custom" as the population type you will be evolving models
		and will use the genetic operators defined in the KrigingFactory class -->  
    <Option key="populationType" value="doubleVector"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <!-- See the documentaion for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="creationFcn" value="@gacreationuniform"/>  
      <Option key="crossoverFcn" value="@crossoverheuristic"/>  
      <Option key="mutationFcn" value="@mutationadaptfeasible"/>  
      <!--			 <Option key="creationFcn" value="createInitialPopulation"/>
			<Option key="crossoverFcn" value="crossover"/>
			<Option key="mutationFcn" value="mutation"/> 			-->  
      <!-- See the documentaion for possible regression and correlation functions -->  
      <Option key="regressionFunction" value="regpoly1"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <BasisFunction>corrgauss</BasisFunction> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build kriging models using PSO -->  
  <ModelBuilder id="krigingpso" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="PSOtOptimizer"> 
      <Option key="typePSO" value="0"/>  
      <Option key="seedPSO" value="1"/>  
      <Option key="popSize" value="10"/>  
      <Option key="maxiters" value="10"/>  
      <Option key="epochInertia" value="8"/>  
      <Option key="gradientTermination" value="8"/> 
    </Optimizer>  
    <!-- See the documentaion for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="regressionFunction" value="regpoly1"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <BasisFunction>corrgauss</BasisFunction> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build kriging models using NSGA-II, requires a multi-output or multi-measure setup -->  
  <ModelBuilder id="krigingnsga" type="ParetoModelBuilder" combineOutputs="true"> 
    <Option key="restartStrategy" value="model"/>  
    <Option key="populationSize" value="30"/>  
    <Option key="maxGenerations" value="30"/>  
    <Option key="plotParetoFront" value="false"/>  
    <Option key="paretoMode" value="true"/>  
    <!-- See the documentaion for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="regressionFunction" value="regpoly1"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <BasisFunction>corrgauss</BasisFunction> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build kriging models randomly, useful as a baseline comparison -->  
  <ModelBuilder id="krigingrandom" type="RandomModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!-- Build 100 random models before restarting -->  
    <Option key="runSize" value="100"/>  
    <!-- See the documentaion for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="regressionFunction" value="regpoly1"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <BasisFunction>corrgauss</BasisFunction> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build blind kriging models -->  
  <ModelBuilder id="blindkriging" type="ModelBuilder" combineOutputs="false"> 
    <Option key="nBestModels" value="1"/>  
    <!-- See the documentation for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="type" value="BlindKriging"/>  
      <Option key="regressionFunction" value="regpoly0"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <Option key="hyperparameters0" value="0.5"/>  
      <BasisFunction>corrgauss</BasisFunction>  
      <Optimizer>fminconWithDerivatives</Optimizer> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build kriging models using the maximum likelihood to set the thetas -->  
  <ModelBuilder id="kriging" type="ModelBuilder" combineOutputs="false"> 
    <Option key="nBestModels" value="1"/>  
    <!-- See the documentation for possible regression and correlation functions -->  
    <ModelFactory type="KrigingFactory"> 
      <Option key="regressionFunction" value="regpoly0"/>  
      <Option key="multipleBasisFunctionsAllowed" value="false"/>  
      <!--<Option key="hyperparameters0" value="0.5" />-->  
      <BasisFunction>corrgauss</BasisFunction>  
      <!-- Alternative Basis Functions (correlation functions) -->  
      <!--<BasisFunction>correxp</BasisFunction>-->  
      <!--<BasisFunction>corrgaussp</BasisFunction>-->  
      <!-- likelihood function to use (default: @marginalLikelihood): -->  
      <!-- <Option key="hpLikelihood" value="@pseudoLikelihood" /> -->  
      <!-- Enable the next set of options for noisy data (regression) -->  
      <!--<Option key="lambda0" value="-5"/>-->  
      <!-- initial value (required) -->  
      <!--<Option key="lambdaBounds" value="[-15; 0]"/>-->  
      <!-- bounds (optional) -->  
      <Optimizer>fminconWithDerivatives</Optimizer> 
    </ModelFactory> 
  </ModelBuilder>  
  <BasisFunction id="corrgauss" type="BasisFunction" name="corrgauss"> 
    <Parameter name="theta" min="-2" max="2" scale="log" duplicate="true"/> 
  </BasisFunction>  
  <BasisFunction id="corrmatern32" type="BasisFunction" name="corrmatern32"> 
    <Parameter name="ell" min="-2" max="2" scale="log" duplicate="true"/> 
  </BasisFunction>  
  <BasisFunction id="corrmatern52" type="BasisFunction" name="corrmatern52"> 
    <Parameter name="ell" min="-2" max="2" scale="log" duplicate="true"/> 
  </BasisFunction>  
  <BasisFunction id="correxp" type="BasisFunction" name="correxp"> 
    <Parameter name="theta" min="-2" max="2" scale="log" duplicate="true"/> 
  </BasisFunction>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Build spline models using a GA -->  
  <ModelBuilder id="splinesgenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Option key="populationType" value="doubleVector"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory id="spline" type="SplineFactory"> 
      <Option key="creationFcn" value="@gacreationuniform"/>  
      <Option key="crossoverFcn" value="@crossoverheuristic"/>  
      <Option key="mutationFcn" value="@mutationadaptfeasible"/>  
      <!-- <Option key="creationFcn" value="createInitialPopulation"/>
			<Option key="crossoverFcn" value="crossover"/>
			<Option key="mutationFcn" value="mutation"/> -->  
      <Option key="smoothingBounds" value="0,1"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build spline models using the Simulated Annealing modelbuilder -->  
  <ModelBuilder id="splinessim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabSimAnnealing"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="spline" type="SplineFactory"> 
      <Option key="smoothingBounds" value="0,1"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build spline models using the Pattern Search modelbuilder -->  
  <ModelBuilder id="splinesps" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <ModelFactory id="spline" type="SplineFactory"> 
      <Option key="smoothingBounds" value="0,1"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Use the Matlab optimization toolbox to build spline models -->  
  <ModelBuilder id="splinesoptim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabOptimizer"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="spline" type="SplineFactory"> 
      <Option key="smoothingBounds" value="0,1"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Simple linear/cubic/nearest neighbour interpolation models for scattered data.  For one D uses interp1, for nD uses griddata(n) -->  
  <ModelBuilder id="ipol" type="ModelBuilder" combineOutputs="false"> 
    <ModelFactory id="ipol" type="InterpolationFactory"> 
      <!--  depending on the input dimension options are: linear, nearest, and cubic
			if you are using Matlab r2009 or later you can also use 'natural' -->  
      <Option key="method" value="linear"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Model types available through WEKA.
    Refer to: http://wiki.pentaho.com/display/DATAMINING/Data+Mining+Algorithms+and+Tools+in+Weka for a list of model types -->  
  <ModelBuilder id="weka" type="ModelBuilder" combineOutputs="false"> 
    <ModelFactory type="WEKAFactory"> 
      <!--  The full identifier of the model should be used as shown below -->  
      <Option key="wekaModelType" value="weka.classifiers.functions.RBFRegressor"/>  
      <Option key="options" value=""/>  
      <!--  Example of automatic parameter tuning for RBF -->  
      <!--<Option key="wekaModelType" value="weka.classifiers.meta.CVParameterSelection"/>
            <Option key="options" value="-W weka.classifiers.functions.RBFRegressor -P &quot;R 0.005 0.1 10&quot; -P &quot;N 2 4 3&quot;"/>-->  
      <!-- Example of automatic parameter tuning for J48 (Decision Tree for Classification)-->  
      <!--<Option key="wekaModelType" value="weka.classifiers.meta.CVParameterSelection"/>
            <Option key="options" value="-W weka.classifiers.trees.J48 -P &quot;C 0.1 0.5 5 &quot;"/>-->  
      <!-- Alternative example of a WEKA model -->  
      <!--<Option key="wekaModelType" value="weka.classifiers.functions.SMOreg"/>
            <Option key="options" value="-C 10 -K weka.classifiers.functions.supportVector.RBFKernel"/>-->  
      <!-- Classifier: remember to set classificationMode and numberOfClasses in ContextConfig! -->  
      <!--<Option key="wekaModelType" value="weka.classifiers.trees.RandomForest"/>--> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Extreme Learning Machines -->  
  <ModelBuilder id="elm" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Optimizer>combi</Optimizer>  
    <ModelFactory id="elm" type="ELMFactory"> 
      <!-- minimum number of hidden units  -->  
      <Option key="minHiddenUnits" value="20"/>  
      <!-- Max number of hidden units, improvement attempts will always end here -->  
      <Option key="maxHiddenUnits" value="120"/>  
      <!-- Activation function of the hidden layer -->  
      <Option key="transferFcn" value="sigmoid"/>  
      <!-- Maximum for random inputweights -->  
      <Option key="maxInputWeight" value="20"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <ModelBuilder id="elmdirect" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Optimizer id="opt" type="DirectOptimizer"> 
      <Option key="maxits" value="100"/>  
      <Option key="maxevals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="elm" type="ELMFactory"> 
      <!-- minimum number of hidden units  -->  
      <Option key="minHiddenUnits" value="20"/>  
      <!-- Max number of hidden units, improvement attempts will always end here -->  
      <Option key="maxHiddenUnits" value="120"/>  
      <!-- Activation function of the hidden layer -->  
      <Option key="transferFcn" value="sigmoid"/>  
      <!-- Maximum for random inputweights -->  
      <Option key="maxInputWeight" value="20"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <ModelBuilder id="elmgenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Option key="populationType" value="doubleVector"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory id="elm" type="ELMFactory"> 
      <Option key="creationFcn" value="@gacreationuniform"/>  
      <Option key="crossoverFcn" value="@crossoverheuristic"/>  
      <Option key="mutationFcn" value="@mutationadaptfeasible"/>  
      <!-- minimum number of hidden units  -->  
      <Option key="minHiddenUnits" value="20"/>  
      <!-- Max number of hidden units, improvement attempts will always end here -->  
      <Option key="maxHiddenUnits" value="120"/>  
      <!-- Activation function of the hidden layer -->  
      <Option key="transferFcn" value="sigmoid"/>  
      <!-- Maximum for random inputweights -->  
      <Option key="maxInputWeight" value="20"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Use a custom evolutionary-like strategy to generate ANN models, this is much faster than the GA approach
	      but not necessarily better -->  
  <ModelBuilder id="ann" type="SequentialModelBuilder" combineOutputs="false"> 
    <Option key="maximumRunLength" value="15"/>  
    <!-- Degeneration of score if a model gets older -->  
    <Option key="decay" value=".99"/>  
    <!-- Size of the best model history -->  
    <Option key="historySize" value="6"/>  
    <!-- One of best, last. When set to best the best `historySize' models are kept,
		 - - when set to last, the last `historySize' models are kept -->  
    <Option key="strategy" value="best"/>  
    <ModelFactory id="ann" type="ANNFactory"> 
      <!--initial hidden layer dimension-->  
      <Option key="initialSize" value="3,3"/>  
      <!--comma separated list of allowed learning rules-->  
      <Option key="allowedLearningRules" value="trainbr"/>  
      <!--performance function to use, empty means use the matlab default-->  
      <Option key="performFcn" value=""/>  
      <!--how many epochs to train for-->  
      <Option key="epochs" value="300"/>  
      <!--max time to train for-->  
      <Option key="trainingTime" value="Inf"/>  
      <!--range of initial random weights-->  
      <Option key="initWeightRange" value="-0.8,0.8"/>  
      <!--mutation changes x neurons at a time (in a random layer) with x in [lb ub]-->  
      <Option key="hiddenUnitDelta" value="-2,3"/>  
      <!--train until the error reaches this goal-->  
      <Option key="trainingGoal" value="0"/>  
      <!--show training progress every x epochs, set to NaN to disable-->  
      <Option key="trainingProgress" value="NaN"/>  
      <!--How to train the network, one of 'auto' or 'earlyStopping'
				auto: train with early stopping unless regularization is employed
				Set to any other value for simply training on all the data, doing nothing special -->  
      <Option key="trainMethod" value="auto"/>  
      <!--the training set - validation set - testset ratios-->  
      <Option key="earlyStoppingRatios" value="0.80,0.20,0"/>  
      <!-- Transfer function to use for all hidden layers and the output layer
			So should be a list of max 2 items -->  
      <Option key="transferFunctionTemplate" value="tansig,purelin"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!--Use the matlab gads toolbox to select ANN parameters using a GA -->  
  <ModelBuilder id="anngenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="continue"/>  
    <!--See that matlab gads toolbox documentation for more information on the options-->  
    <Option key="populationType" value="custom"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory id="ann" type="ANNFactory"> 
      <Option key="crossoverFcn" value="crossover"/>  
      <Option key="mutationFcn" value="mutation"/>  
      <Option key="creationFcn" value="createInitialPopulation"/>  
      <!--initial hidden layer dimension-->  
      <Option key="initialSize" value="3,3"/>  
      <!--comma separated list of allowed learning rules-->  
      <Option key="allowedLearningRules" value="trainbr"/>  
      <!--performance function to use, empty means use the matlab default-->  
      <Option key="performFcn" value=""/>  
      <!--how many epochs to train for-->  
      <Option key="epochs" value="300"/>  
      <!--max time to train for-->  
      <Option key="trainingTime" value="Inf"/>  
      <!--range of initial random weights-->  
      <Option key="initWeightRange" value="-0.8,0.8"/>  
      <!--mutation changes x neurons at a time (in a random layer) with x in [lb ub]-->  
      <Option key="hiddenUnitDelta" value="-2,3"/>  
      <!--train until the error reaches this goal-->  
      <Option key="trainingGoal" value="0"/>  
      <!--show training progress every x epochs, set to NaN to disable-->  
      <Option key="trainingProgress" value="NaN"/>  
      <!--How to train the network, one of 'auto' or 'earlyStopping'
				auto: train with early stopping unless regularization is employed
				Set to any other value for simply training on all the data, doing nothing special -->  
      <Option key="trainMethod" value="auto"/>  
      <!--the training set - validation set - testset ratios-->  
      <Option key="earlyStoppingRatios" value="0.80,0.20,0"/>  
      <!-- Transfer function to use for all hidden layers and the output layer
			So should be a list of max 2 items -->  
      <Option key="transferFunctionTemplate" value="tansig,purelin"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Fixed ANN model builder, allows you to choose the hidden layer structure manually Thus there is no optimization algorithm involved. -->  
  <ModelBuilder id="annfixed" type="ModelBuilder" combineOutputs="false"> 
    <ModelFactory id="ann" type="ANNFactory"> 
      <Option key="allowedLearningRules" value="trainbr"/>  
      <Option key="initialSize" value="3,3"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Random ANN model builder, usefull as a baseline comparison -->  
  <ModelBuilder id="annrandom" type="RandomModelBuilder" combineOutputs="false"> 
    <!--This many iterations before allowing new samples-->  
    <Option key="runSize" value="10"/>  
    <ModelFactory id="ann" type="ANNFactory"> 
      <Option key="allowedLearningRules" value="trainbr,trainlm,trainscg"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!--Use the matlab gads toolbox to select ANN parameters using a GA (based on the FANN library) -->  
  <ModelBuilder id="fanngenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="continue"/>  
    <!--See that matlab gads toolbox documentation for more information on the options-->  
    <Option key="populationType" value="custom"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory id="fann" type="FANNFactory"> 
      <Option key="crossoverFcn" value="crossover"/>  
      <Option key="mutationFcn" value="mutation"/>  
      <Option key="creationFcn" value="createInitialPopulation"/>  
      <!--initial hidden layer dimension-->  
      <Option key="initialSize" value="4,4"/>  
      <!--how many epochs to train for-->  
      <Option key="epochs" value="1500"/>  
      <!--range of initial random weights-->  
      <Option key="initWeightRange" value="-0.8,0.8"/>  
      <!--mutation changes x neurons at a time (in a random layer) with x in [lb ub]-->  
      <Option key="hiddenUnitDelta" value="-2,2"/>  
      <!--train until the error reaches this goal-->  
      <Option key="trainingGoal" value="0"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!--Use the matlab gads toolbox to select LSSVM parameters using a GA (based on LSSVM-lab) -->  
  <ModelBuilder id="lssvmgenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Option key="populationType" value="doubleVector"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory id="LSSVM" type="SVMFactory"> 
      <Option key="creationFcn" value="@gacreationuniform"/>  
      <Option key="crossoverFcn" value="@crossoverheuristic"/>  
      <Option key="mutationFcn" value="@mutationadaptfeasible"/>  
      <!-- <Option key="creationFcn" value="createInitialPopulation"/>
			<Option key="crossoverFcn" value="crossover"/>
			<Option key="mutationFcn" value="mutation"/> -->  
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Use the matlab gads toolbox to select LSSVM parameters using Pattern Search -->  
  <ModelBuilder id="lssvmps" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!--See that matlab gads toolbox documentation for more information on the options-->  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the matlab optimization toolbox to select LSSVM parameters -->  
  <ModelBuilder id="lssvmoptim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!--See the interface matlab file and the optimization toolbox documentation for more information on the options-->  
    <Optimizer type="MatlabOptimizer"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the PSO toolbox to select LSSVM parameters using Particle Swarm Optimization -->  
  <ModelBuilder id="lssvmpso" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Optimizer type="PSOtOptimizer"> 
      <Option key="typePSO" value="0"/>  
      <Option key="seedPSO" value="1"/>  
      <Option key="popSize" value="10"/>  
      <Option key="maxiters" value="10"/>  
      <Option key="epochInertia" value="8"/>  
      <Option key="gradientTermination" value="8"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the matlab gads toolbox to select LSSVM parameters using simulated annealing -->  
  <ModelBuilder id="lssvmsim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!--See the interface matlab file and the gads toolbox documentation for more information on the options-->  
    <Optimizer type="MatlabSimAnnealing"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the DIviding RECtangles algorithm to optimize the LS-SVM hyperparameters-->  
  <ModelBuilder id="lssvmdirect" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Optimizer id="opt" type="DirectOptimizer"> 
      <Option key="maxits" value="100"/>  
      <Option key="maxevals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Generate LS-SVM models using Efficient Global Optimization (EGO).  This means internally a kriging model is constructed
		to predict where one can expect to find good model parameters -->  
  <ModelBuilder id="lssvmego" type="EGOModelBuilder" combineOutputs="false"> 
    <Option key="numIterations" value="10"/>  
    <Option key="initPopSize" value="5"/>  
    <Option key="restartStrategy" value="continue"/>  
    <ModelFactory id="LSSVM" type="SVMFactory"> 
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-4,4"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory>  
    <!-- Optimizer for the internal kriging model -->  
    <Optimizer>fminconWithDerivatives</Optimizer>  
    <!-- SequentialDesign to use -->  
    <SequentialDesign>expectedImprovement</SequentialDesign> 
  </ModelBuilder>  
  <!--Generate random LSSVM models, useful as a baseline comparison -->  
  <ModelBuilder id="lssvmrandom" type="RandomModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Option key="runSize" value="20"/>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="lssvm"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!--Use the matlab gads toolbox to select SVM parameters using a GA (based on libsvm) -->  
  <ModelBuilder id="svmgenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!--See the interface matlab file and the gads toolbox documentation for more information on the options-->  
    <Option key="populationType" value="doubleVector"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="creationFcn" value="@gacreationuniform"/>  
      <Option key="crossoverFcn" value="@crossoverheuristic"/>  
      <Option key="mutationFcn" value="@mutationadaptfeasible"/>  
      <!-- <Option key="creationFcn" value="createInitialPopulation"/>
			<Option key="crossoverFcn" value="crossover"/>
			<Option key="mutationFcn" value="mutation"/>-->  
      <Option key="backend" value="libSVM"/>  
      <Option key="type" value="epsilon-SVR"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-4,4"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the matlab gads toolbox to select SVM parameters using Pattern Search -->  
  <ModelBuilder id="svmps" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!--See the interface matlab file and the gads toolbox documentation for more information on the options-->  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="libSVM"/>  
      <Option key="type" value="epsilon-SVR"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the matlab gads toolbox to select SVM parameters using simulated annealing -->  
  <ModelBuilder id="svmsim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!--See the interface matlab file and the gads toolbox documentation for more information on the options-->  
    <Optimizer type="MatlabSimAnnealing"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="libSVM"/>  
      <Option key="type" value="epsilon-SVR"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the matlab optimization toolbox to select SVM parameters -->  
  <ModelBuilder id="svmoptim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <!--See the interface matlab file and the optimization toolbox documentation for more
			information on the options-->  
    <Optimizer type="MatlabOptimizer"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="libSVM"/>  
      <Option key="type" value="epsilon-SVR"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the PSO toolbox to select SVM parameters using Particle Swarm Optimization -->  
  <ModelBuilder id="svmpso" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Optimizer id="pso" type="PSOtOptimizer"> 
      <Option key="typePSO" value="0"/>  
      <Option key="seedPSO" value="1"/>  
      <Option key="popSize" value="10"/>  
      <Option key="maxiters" value="10"/>  
      <Option key="epochInertia" value="8"/>  
      <Option key="gradientTermination" value="8"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="libSVM"/>  
      <Option key="type" value="epsilon-SVR"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the DIviding RECtangles algorithm to optimize the SVM hyperparameters-->  
  <ModelBuilder id="svmdirect" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Optimizer id="opt" type="DirectOptimizer"> 
      <Option key="maxits" value="100"/>  
      <Option key="maxevals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="libSVM"/>  
      <Option key="type" value="epsilon-SVR"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!--Use the DIviding RECtangles algorithm to optimize the classification SVM hyperparameters-->  
  <ModelBuilder id="svmdirectC" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Optimizer id="opt" type="DirectOptimizer"> 
      <Option key="maxits" value="100"/>  
      <Option key="maxevals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="libSVM"/>  
      <Option key="mode" value="classification"/>  
      <Option key="probabilistic" value="true"/>  
      <Option key="type" value="C-SVC"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Generate random SVMs, useful as a baseline comparison -->  
  <ModelBuilder id="svmrandom" type="RandomModelBuilder" combineOutputs="false"> 
    <!-- Plot the optimization surface, visualizes the search through the parameter space (2D only) -->  
    <Option key="plotOptimSurface" value="false"/>  
    <Option key="runSize" value="20"/>  
    <ModelFactory id="SVM" type="SVMFactory"> 
      <Option key="backend" value="libSVM"/>  
      <Option key="type" value="epsilon-SVR"/>  
      <Option key="kernel" value="rbf"/>  
      <Option key="kernelParamBounds" value="-2,2"/>  
      <Option key="regParamBounds" value="-5,5"/>  
      <Option key="nu" value="0.01"/>  
      <Option key="epsilon" value="0"/>  
      <Option key="stoppingTolerance" value="1e-6"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!--Genetic model builder for Radial Basis Function Neural networks  -->  
  <ModelBuilder id="rbfnngenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Option key="populationType" value="doubleVector"/>  
    <Option key="populationSize" value="10"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <ModelFactory id="rbfnn" type="RBFNNFactory"> 
      <Option key="creationFcn" value="@gacreationuniform"/>  
      <Option key="crossoverFcn" value="@crossoverheuristic"/>  
      <Option key="mutationFcn" value="@mutationadaptfeasible"/>  
      <!--		<Option key="creationFcn" value="createInitialPopulation"/>
			<Option key="crossoverFcn" value="crossover"/>
			<Option key="mutationFcn" value="mutation"/> -->  
      <!--Error goal when constructing the network-->  
      <Option key="goal" value="0"/>  
      <!--Initial value for the spread -->  
      <Option key="spread" value="1"/>  
      <!--Spread bounds -->  
      <Option key="spreadBounds" value="0.0001,30"/>  
      <!--Maximum number of neurons to use per network-->  
      <Option key="maxNeurons" value="500"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build Radial Basis Function Neural networks using Pattern Search -->  
  <ModelBuilder id="rbfnnps" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <ModelFactory id="rbfnn" type="RBFNNFactory"> 
      <!--Error goal when constructing the network-->  
      <Option key="goal" value="0"/>  
      <!--Initial value for the spread -->  
      <Option key="spread" value="1"/>  
      <!--Spread bounds -->  
      <Option key="spreadBounds" value="0.0001,30"/>  
      <!--Maximum number of neurons to use per network-->  
      <Option key="maxNeurons" value="500"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- Build Radial Basis Function Neural networks using Simulated Annealing -->  
  <ModelBuilder id="rbfnnsim" type="OptimizerModelBuilder" combineOutputs="false"> 
    <!-- Re-start strategy for resuming the optimization process between sampling iterations.
		     One of 'random','continue','model' and 'intelligent' (Default).  See the docs for more information -->  
    <Option key="restartStrategy" value="intelligent"/>  
    <Optimizer type="MatlabSimAnnealing"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <ModelFactory id="rbfnn" type="RBFNNFactory"> 
      <!--Error goal when constructing the network-->  
      <Option key="goal" value="0"/>  
      <!--Initial value for the spread -->  
      <Option key="spread" value="1"/>  
      <!--Spread bounds -->  
      <Option key="spreadBounds" value="0.0001,30"/>  
      <!--Maximum number of neurons to use per network-->  
      <Option key="maxNeurons" value="500"/> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!--A heterogeneous genetic model builder.  Uses a genetic algorithm with speciation (island model)
	      to evolve different model types together.  The models types compete against each other until the
	      best model prevails. So this model builder is a way to automatically select the best model type. -->  
  <ModelBuilder id="heterogenetic" type="GeneticModelBuilder" combineOutputs="false"> 
    <Option key="restartStrategy" value="continue"/>  
    <Option key="populationType" value="custom"/>  
    <!-- the population size must match the number of model interfaces minus 1 -->  
    <Option key="populationSize" value="10,10,10"/>  
    <Option key="maxGenerations" value="10"/>  
    <Option key="crossoverFraction" value="0.7"/>  
    <Option key="eliteCount" value="1"/>  
    <Option key="stallGenLimit" value="4"/>  
    <Option key="stallTimeLimit" value="Inf"/>  
    <Option key="migrationDirection" value="forward"/>  
    <Option key="migrationFraction" value="0.1"/>  
    <Option key="migrationInterval" value="4"/>  
    <!-- Do we want to prevent any model type going completely extinct -->  
    <Option key="extinctionPrevention" value="yes"/>  
    <ModelFactory id="hetero" type="HeterogeneousFactory"> 
      <Option key="creationFcn" value="createInitialPopulation"/>  
      <Option key="crossoverFcn" value="crossover"/>  
      <Option key="mutationFcn" value="mutation"/>  
      <ModelFactory id="Ensemble" type="EnsembleFactory"> 
        <Option key="crossoverFcn" value="crossover"/>  
        <Option key="mutationFcn" value="mutation"/>  
        <!-- the maximum ensemble size -->  
        <Option key="maxSize" value="4"/>  
        <!-- Ensemble members should differ this much percent -->  
        <Option key="equalityThreshold" value="0.05"/> 
      </ModelFactory>  
      <ModelFactory id="LSSVM" type="SVMFactory"> 
        <Option key="creationFcn" value="createInitialPopulation"/>  
        <Option key="crossoverFcn" value="crossover"/>  
        <Option key="mutationFcn" value="mutation"/>  
        <Option key="backend" value="lssvm"/>  
        <Option key="kernel" value="rbf"/>  
        <Option key="kernelParamBounds" value="-2,2"/>  
        <Option key="regParamBounds" value="-5,5"/> 
      </ModelFactory>  
      <ModelFactory type="RationalFactory"> 
        <Option key="crossoverFcn" value="crossover"/>  
        <Option key="mutationFcn" value="mutation"/>  
        <Option key="creationFcn" value="createInitialPopulation"/>  
        <Option key="weightBounds" value="1,40"/>  
        <Option key="percentBounds" value="1,100"/>  
        <Option key="percentRational" value="70"/>  
        <Option key="frequencyVariable" value="off"/>  
        <Option key="basis" value="power"/> 
      </ModelFactory>  
      <ModelFactory type="RBFFactory"> 
        <Option key="crossoverFcn" value="crossover"/>  
        <Option key="mutationFcn" value="mutation"/>  
        <Option key="creationFcn" value="createInitialPopulation"/>  
        <!-- Bounds for the shape parameter -->  
        <Option key="multipleBasisFunctionsAllowed" value="true"/>  
        <BasisFunction>rbfGaussian</BasisFunction>  
        <BasisFunction>rbfMultiquadric</BasisFunction>  
        <BasisFunction>rbfExponential</BasisFunction>  
        <Option key="regression" value="-1,0,1,2"/>  
        <Option key="solver" value="directFit"/> 
      </ModelFactory> 
    </ModelFactory> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Combines the generation of multiple surrogate model types in one iteration
    and optionally build an ensemble of the best models of each type -->  
  <ModelBuilder id="heterosequential" type="CombinedModelBuilder" combineOutputs="false"> 
    <Option key="buildEnsembleModel" value="true"/>  
    <ModelBuilder>ann</ModelBuilder>  
    <ModelBuilder>lssvmps</ModelBuilder>  
    <ModelBuilder>kriging</ModelBuilder>  
    <ModelBuilder>rbf</ModelBuilder>  
    <ModelFactory id="Ensemble" type="EnsembleFactory"/> 
  </ModelBuilder>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Initial design without any samples -->  
  <InitialDesign id="empty" type="EmptyDesign"/>  
  <!-- Latin Hypercube DOE -->  
  <InitialDesign id="lhd" type="LatinHypercubeDesign"> 
    <!-- how many points to generate -->  
    <Option key="points" value="20"/>  
    <!--<Option key="weight" value="0.5"/>-->  
    <!--<Option key="coolingFactor" value="0.9"/>-->  
    <!--<Option key="p" value="5.0"/>--> 
  </InitialDesign>  
  <!-- Latin Hypercube DOE (created with Translational Propagation algorithm -->  
  <InitialDesign id="tplhd" type="LatinHypercubeDesign"> 
    <!-- how many points to generate -->  
    <Option key="points" value="20"/> 
  </InitialDesign>  
  <!-- Specifies a simple Factorial Design (uniform grid) -->  
  <InitialDesign id="factorial" type="FactorialDesign"> 
    <!-- how many points to generate for each dimension as a vector -->  
    <!-- a scalar value (l) is the same as [l l ... l] (length of input dimension) -->  
    <Option key="levels" value="3"/> 
  </InitialDesign>  
  <!-- Very simple design, only 2 samples for any dimensionality [-1,-1,...] and [1,1,...]-->  
  <InitialDesign id="crosscorner" type="CrossCornerDesign"/>  
  <!-- Specifies a trivial Random design -->  
  <InitialDesign id="random" type="RandomDesign"> 
    <Option key="points" value="20"/> 
  </InitialDesign>  
  <!-- Specifies a trivial Random design -->  
  <InitialDesign id="hilbertcurve" type="HilbertCurve"> 
    <Option key="order" value="3"/>  
    <Option key="allowClosedLoop" value="false"/> 
  </InitialDesign>  
  <!-- Specifies a combined Latin HyperCube and FactorialDesign -->  
  <InitialDesign id="lhdWithCornerPoints" type="CombinedDesign"> 
    <!-- Select samples in a Latin Hypercube Design -->  
    <InitialDesign type="TPLatinHypercubeDesign"> 
      <!-- how many points to generate -->  
      <Option key="points" value="10"/>  
      <!--<Option key="weight" value="0.5"/>-->  
      <!--<Option key="coolingFactor" value="0.9"/>-->  
      <!--<Option key="p" value="5.0"/>--> 
    </InitialDesign>  
    <InitialDesign type="FactorialDesign"> 
      <!-- how many points to generate for each dimension as a vector -->  
      <!-- a scalar value (l) is the same as [l l ... l] (length of input dimension) -->  
      <Option key="levels" value="2"/> 
    </InitialDesign> 
  </InitialDesign>  
  <!-- Use an existing dataset as the initial design -->  
  <InitialDesign id="dataset" type="DatasetDesign"> 
    <!-- Where should we load the dataset from? -->  
    <Option key="filename" value="D:\Google Drive\My Docs\UD\Proyecto de Grado\Trabajo\Objetivo 2\Surrogate Modeling\output\kriging_default_2016.01.13_01-44-57\samples.txt"/>  
    <!-- Does the dataset also contain responses? (instead of only the inputs) 
		     If so, hasOutputs must be set to yes and the range of the inputs in the file must
		     match the range of the simulator.  If not, the range of the inputs must be [-1 1].
		-->  
    <Option key="hasOutputs" value="yes"/> 
  </InitialDesign>  
  <!-- Use space-filling sequential design methods to generate -->  
  <InitialDesign id="sequentialinitialdesign" type="SequentialInitialDesign"> 
    <Option key="points" value="24"/>  
    <!-- Some Sequential designs do require specific start points. This can be specified here -->  
    <InitialDesign>crosscorner</InitialDesign>  
    <!-- Space filling Sequential design method -->  
    <SequentialDesign>density-optimizer</SequentialDesign> 
  </InitialDesign>  
  <!-- /////////////////////////////////////////////////////////////////////// -->  
  <!-- Different optimizers that can be used in other components, others are possible (See wiki)  -->  
  <!-- The DIviding RECtangles (DIRECT) optimization technique of Donald D. R. Jones -->  
  <Optimizer id="directOptimizer" type="DirectOptimizer"> 
    <Option key="maxevals" value="1000"/>  
    <Option key="maxits" value="300"/> 
  </Optimizer>  
  <!-- Matlab Pattern search (patternsearch function of Matlab Direct Search toolbox) -->  
  <Optimizer id="patternsearch" type="MatlabPatternSearch"> 
    <Option key="maxIter" value="500"/>  
    <Option key="maxFunEvals" value="1000"/>  
    <Option key="completePoll" value="on"/> 
  </Optimizer>  
  <!-- Matlab fmincon (active-set) -->  
  <Optimizer id="fmincon" type="MatlabOptimizer"> 
    <Option key="gradobj" value="off"/>  
    <Option key="derivativecheck" value="off"/>  
    <Option key="diagnostics" value="off"/>  
    <Option key="algorithm" value="active-set"/>  
    <Option key="functionTolerance" value="1e-10"/>  
    <Option key="maxFunEvals" value="1000"/>  
    <Option key="maxIter" value="500"/> 
  </Optimizer>  
  <!-- Matlab fmincon (active-set) using derivative information (used for kriging models in SUMO-toolbox) -->  
  <Optimizer id="fminconWithDerivatives" type="MatlabOptimizer"> 
    <Option key="gradobj" value="on"/>  
    <Option key="derivativecheck" value="off"/>  
    <Option key="diagnostics" value="off"/>  
    <Option key="algorithm" value="active-set"/> 
  </Optimizer>  
  <!-- Joint optimization: several techniques, best solution wins. -->  
  <Optimizer id="combi" type="CombiOptimizer"> 
    <Optimizer type="DirectOptimizer"> 
      <Option key="maxevals" value="100"/>  
      <Option key="maxits" value="20"/> 
    </Optimizer>  
    <Optimizer type="MatlabSimAnnealing"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/> 
    </Optimizer>  
    <Optimizer type="MatlabPatternSearch"> 
      <Option key="maxIter" value="100"/>  
      <Option key="maxFunEvals" value="20"/>  
      <Option key="searchMethod" value="GPSPositiveBasis2N"/>  
      <Option key="pollMethod" value="MADSPositiveBasis2N"/> 
    </Optimizer>  
    <Optimizer type="PSOtOptimizer"> 
      <Option key="typePSO" value="0"/>  
      <Option key="seedPSO" value="1"/>  
      <Option key="popSize" value="10"/>  
      <Option key="maxiters" value="10"/>  
      <Option key="epochInertia" value="8"/>  
      <Option key="gradientTermination" value="8"/> 
    </Optimizer> 
  </Optimizer> 
</ToolboxConfiguration>
